---
phase: 02-sentinel-data-access
plan: 02
type: execute
wave: 2
depends_on: ["02-01"]
files_modified:
  - src/queries/__init__.py
  - src/queries/trends.py
  - src/queries/entities.py
  - src/sentinel_client.py
  - tests/test_sentinel_client.py
autonomous: false
requirements: [QUERY-04, QUERY-05]

must_haves:
  truths:
    - "get_alert_trend() returns TrendPoint dataclasses showing alert frequency bucketed by time bins over a configurable period"
    - "get_top_entities() returns EntityCount dataclasses ranked by alert count for accounts, IPs, and hosts"
    - "Aggregation queries use 180s server_timeout (not 60s) to accommodate heavier KQL operators"
    - "All five query methods work against live Sentinel data (verified with real workspace)"
    - "Partial results from any query set truncated=True in metadata envelope"
  artifacts:
    - path: "src/queries/trends.py"
      provides: "KQL templates for alert_trend and alert_trend_total"
      contains: "TEMPLATES"
    - path: "src/queries/entities.py"
      provides: "KQL template for top_entities with parse_json + mv-expand entity extraction"
      contains: "TEMPLATES"
    - path: "src/sentinel_client.py"
      provides: "SentinelClient with get_alert_trend() and get_top_entities() methods added"
      contains: "def get_alert_trend"
    - path: "tests/test_sentinel_client.py"
      provides: "Unit tests for trend and entity query methods"
      contains: "def test_get_alert_trend"
  key_links:
    - from: "src/queries/__init__.py"
      to: "src/queries/trends.py"
      via: "merges trends.TEMPLATES into TEMPLATE_REGISTRY"
      pattern: "from src\\.queries import trends"
    - from: "src/queries/__init__.py"
      to: "src/queries/entities.py"
      via: "merges entities.TEMPLATES into TEMPLATE_REGISTRY"
      pattern: "from src\\.queries import entities"
    - from: "src/sentinel_client.py"
      to: "src/queries/__init__.py"
      via: "uses alert_trend and top_entities templates with 180s timeout"
      pattern: "build_query.*alert_trend|build_query.*top_entities"
---

<objective>
Add trend analysis and entity ranking queries to the SentinelClient, then verify the complete data access layer works against live Sentinel data. This completes Phase 2 by delivering the remaining two query types (QUERY-04, QUERY-05) and validating the entire pipeline end-to-end.

Purpose: Trend and entity queries use heavier KQL operators (summarize+bin, parse_json+mv-expand) that require longer timeouts and produce different result shapes. Verifying against live data confirms the KQL templates, column mappings, and parsing logic all work with real Sentinel tables.

Output: src/queries/trends.py, src/queries/entities.py, extended SentinelClient with get_alert_trend() and get_top_entities(), unit tests, and live verification.
</objective>

<execution_context>
@C:/Users/AlexSandstrom/.claude/get-shit-done/workflows/execute-plan.md
@C:/Users/AlexSandstrom/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02-sentinel-data-access/02-RESEARCH.md
@.planning/phases/02-sentinel-data-access/02-CONTEXT.md
@.planning/phases/02-sentinel-data-access/02-01-SUMMARY.md
@src/models.py
@src/queries/__init__.py
@src/sentinel_client.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add trend and entity query templates, SentinelClient methods, and unit tests</name>
  <files>
    src/queries/trends.py
    src/queries/entities.py
    src/queries/__init__.py
    src/sentinel_client.py
    tests/test_sentinel_client.py
  </files>
  <action>
Add the remaining two domain template modules and extend SentinelClient with trend and entity methods.

**src/queries/trends.py** -- KQL templates dict `TEMPLATES`:
- `alert_trend`: Query SecurityAlert with `ago({time_range})`, `AlertSeverity in ({severity_filter})`, `summarize Count=count() by bin(TimeGenerated, {bin_size}), AlertSeverity`, order by TimeGenerated asc. The `{bin_size}` parameter controls bucketing granularity (e.g., "1d", "1h").
- `alert_trend_total`: Same but without AlertSeverity grouping -- just total count per time bin. `summarize Count=count() by bin(TimeGenerated, {bin_size})`, order by TimeGenerated asc.

**src/queries/entities.py** -- KQL templates dict `TEMPLATES`:
- `top_entities`: Query SecurityAlert with `ago({time_range})`, `AlertSeverity in ({severity_filter})`, `extend EntitiesParsed = parse_json(Entities)`, `mv-expand Entity = EntitiesParsed`, extract EntityType and EntityName using `case()` for account (Entity.Name), ip (Entity.Address), host (Entity.HostName), with fallback `tostring(Entity.Name)`. Filter `where isnotempty(EntityName)` and `where EntityType in ("account", "ip", "host")`. `summarize AlertCount=count(), Severities=make_set(AlertSeverity) by EntityType, EntityName`. Order by AlertCount desc, `take {limit}`.

**src/queries/__init__.py** -- Update to include new modules:
- Import `trends` and `entities` modules.
- Merge `trends.TEMPLATES` and `entities.TEMPLATES` into `TEMPLATE_REGISTRY`.
- Add to `TEMPLATE_TIMEOUTS`: `alert_trend: 180`, `alert_trend_total: 180`, `top_entities: 180` (aggregation queries get longer timeout per user decision).

**src/sentinel_client.py** -- Add two new public methods:

- `get_alert_trend(self, time_window="last_7d", min_severity="Informational", bin_size=None) -> QueryResult | QueryError`: Validate time_window. Auto-select bin_size if not provided: "1h" for last_1h/last_24h, "1d" for last_3d/last_7d/last_14d/last_30d. Build query via "alert_trend" template with time_range, severity_filter, bin_size params. Execute with 180s server_timeout. Parse rows into TrendPoint dataclasses (timestamp from bin column, count from Count, severity from AlertSeverity). Wrap in metadata envelope.

- `get_top_entities(self, time_window="last_7d", min_severity="Informational", limit=10) -> QueryResult | QueryError`: Validate time_window. Clamp limit to MAX_LIMITS["top_entities"]. Build query via "top_entities" template. Execute with 180s server_timeout. Parse rows into EntityCount dataclasses (entity_type from EntityType, entity_name from EntityName, count from AlertCount). Wrap in metadata envelope.

- Private `_parse_trend_points(self, tables) -> list[TrendPoint]`: Parse LogsTable rows into TrendPoint dataclasses. Map TimeGenerated->timestamp, Count->count, AlertSeverity->severity (if present).

- Private `_parse_entity_counts(self, tables) -> list[EntityCount]`: Parse LogsTable rows into EntityCount dataclasses. Map EntityType->entity_type, EntityName->entity_name, AlertCount->count.

**tests/test_sentinel_client.py** -- Add tests for new methods:
- Test `get_alert_trend()` returns QueryResult with TrendPoint dataclasses and metadata.
- Test `get_alert_trend()` auto-selects bin_size based on time_window (1h for short windows, 1d for longer).
- Test `get_top_entities()` returns QueryResult with EntityCount dataclasses ranked by count.
- Test `get_top_entities()` clamps limit to hard cap.
- Test aggregation queries use 180s timeout (verify the timeout value passed to query_workspace).
  </action>
  <verify>
Run `pytest tests/test_sentinel_client.py -v` -- all tests pass (including existing incident/alert tests from Plan 01 and new trend/entity tests).
Run `pytest -v` -- all tests pass.
Run `ruff check src/ tests/` -- no linting errors.
Run `python -c "from src.queries import TEMPLATE_REGISTRY; print(f'{len(TEMPLATE_REGISTRY)} templates'); assert 'alert_trend' in TEMPLATE_REGISTRY; assert 'top_entities' in TEMPLATE_REGISTRY"` -- 9 templates registered, assertions pass.
  </verify>
  <done>
SentinelClient has all five query methods: query_incidents, get_incident_detail, query_alerts, get_alert_trend, get_top_entities. Trend queries auto-select bin_size. Entity queries use parse_json+mv-expand KQL pattern. Aggregation queries use 180s server_timeout. Template registry contains 9 templates across 4 domain modules. All unit tests pass.
  </done>
</task>

<task type="checkpoint:human-verify" gate="blocking">
  <name>Task 2: Verify all query methods against live Sentinel data</name>
  <files>tests/smoke_live.py</files>
  <action>
Create and run a temporary smoke test script (tests/smoke_live.py) that exercises each SentinelClient method against the live Sentinel workspace. The script loads settings from .env, creates a SentinelClient, and calls each of the 5 query methods with last_30d time window and Informational severity threshold. It prints structured output showing success/failure, result counts, and sample data for each method. Human reviews the output to confirm KQL templates, column mappings, and response parsing all work with real Sentinel data.

What was built: Complete Sentinel data access layer with 5 query methods covering incidents, alerts, trends, and entities. All methods use typed dataclasses, metadata envelopes, severity threshold filtering, and predefined time windows. Unit tests pass with mocked data.
  </action>
  <verify>
Review the smoke test output:
- Do incident results contain expected fields (number, title, severity, status)?
- Do alert results use correct severity values (not empty)?
- Do trend results show data points with counts?
- Do entity results show ranked entities (may be empty if training lab lacks entity data -- that is OK)?
- Are relative timestamps reasonable ("X days ago", not raw datetimes)?
- Does the metadata envelope show total count and truncated flag?
If any method produces errors, note the error code and message. Empty results are acceptable if the query executes without errors.
  </verify>
  <done>All five SentinelClient methods execute successfully against live Sentinel workspace. Results contain correctly typed dataclasses with human-readable timestamps. Metadata envelopes show accurate total counts and truncated flags. Phase 2 data access layer is verified and ready for Phase 3 AI orchestration.</done>
</task>

</tasks>

<verification>
1. `pytest -v` passes all tests (config + models + queries + sentinel_client)
2. `ruff check src/ tests/` reports no errors
3. Template registry contains 9 templates across 4 domains (incidents: 5, alerts: 1, trends: 2, entities: 1)
4. All five SentinelClient methods execute against live Sentinel workspace without errors
5. Results contain typed dataclasses with human-readable relative timestamps
6. Metadata envelope present on every successful result (total, query_ms, truncated)
7. Aggregation queries use 180s server_timeout
</verification>

<success_criteria>
- get_alert_trend() returns TrendPoint dataclasses with timestamp/count/severity bucketed by time
- get_top_entities() returns EntityCount dataclasses ranked by alert count
- All 9 KQL templates render correctly with parameter substitution
- Live smoke test executes all 5 query methods against real Sentinel workspace
- Partial result handling verified (truncated flag set correctly)
- Complete Phase 2 data access layer ready for Phase 3 AI orchestration
</success_criteria>

<output>
After completion, create `.planning/phases/02-sentinel-data-access/02-02-SUMMARY.md`
</output>
