---
phase: 03-ai-orchestration-integration
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - src/tools.py
  - src/tool_handlers.py
  - src/prompts.py
  - tests/test_tools.py
  - tests/test_tool_handlers.py
  - tests/test_prompts.py
  - requirements.txt
autonomous: true
requirements: [ORCH-02, ORCH-03]
user_setup: []

must_haves:
  truths:
    - "Each SentinelClient method has exactly one matching tool definition with correct parameter schema"
    - "ToolDispatcher routes tool names to SentinelClient methods and returns serialized JSON results"
    - "ToolDispatcher silently retries once on retryable errors before returning the error"
    - "System prompt enforces hard no-fabrication rule and footnote-style reasoning transparency"
    - "Unknown tool names return a structured error, not an exception"
  artifacts:
    - path: "src/tools.py"
      provides: "5 tool definitions in OpenAI tools format"
      contains: "SENTINEL_TOOLS"
    - path: "src/tool_handlers.py"
      provides: "Tool dispatch with retry logic"
      contains: "class ToolDispatcher"
    - path: "src/prompts.py"
      provides: "System prompt and templates"
      contains: "SYSTEM_PROMPT"
    - path: "tests/test_tools.py"
      provides: "Tool schema validation tests"
    - path: "tests/test_tool_handlers.py"
      provides: "Dispatch and retry tests"
    - path: "tests/test_prompts.py"
      provides: "Prompt content tests"
  key_links:
    - from: "src/tool_handlers.py"
      to: "src/sentinel_client.py"
      via: "ToolDispatcher._dispatch_map calls SentinelClient methods"
      pattern: "self\\._client\\.(query_incidents|get_incident_detail|query_alerts|get_alert_trend|get_top_entities)"
    - from: "src/tools.py"
      to: "src/tool_handlers.py"
      via: "Tool names in SENTINEL_TOOLS match keys in ToolDispatcher._dispatch_map"
      pattern: "query_incidents|get_incident_detail|query_alerts|get_alert_trend|get_top_entities"
    - from: "src/prompts.py"
      to: "src/tools.py"
      via: "System prompt references tool capabilities that match SENTINEL_TOOLS definitions"
---

<objective>
Create the tool definition layer, dispatch handler, and system prompt for the AI orchestration.

Purpose: These are the building blocks that Plan 03-02 (ChatSession + CLI) depends on. Tool definitions tell gpt-4o what Sentinel queries are available. The dispatcher routes tool calls to SentinelClient methods with retry logic. The system prompt enforces grounding rules, no-fabrication policy, and footnote-style transparency.

Output: src/tools.py, src/tool_handlers.py, src/prompts.py with full test coverage. Also adds tiktoken to requirements.txt (needed by Plan 03-02 but install now to keep requirements current).
</objective>

<execution_context>
@C:/Users/AlexSandstrom/.claude/get-shit-done/workflows/execute-plan.md
@C:/Users/AlexSandstrom/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/03-ai-orchestration-integration/03-CONTEXT.md
@.planning/phases/03-ai-orchestration-integration/03-RESEARCH.md
@src/sentinel_client.py
@src/models.py
@src/queries/__init__.py
@src/config.py
@tests/conftest.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Tool definitions and dispatch handler</name>
  <files>src/tools.py, src/tool_handlers.py, requirements.txt</files>
  <action>
**src/tools.py** -- Create SENTINEL_TOOLS list with 5 tool definitions in OpenAI `tools` parameter format. Each tool maps 1:1 to a SentinelClient method:

1. `query_incidents` -- params: time_window (enum of TIME_WINDOWS keys), min_severity (enum: High, Medium, Low, Informational), limit (integer, default 20, max 100). Description should help the LLM choose this for questions about incident lists, recent security incidents, "what's happening" queries.

2. `get_incident_detail` -- params: incident_ref (oneOf: integer for incident number, string for name search). Description should guide the LLM to use this for "tell me about incident X", "details on incident 42", or follow-up drill-downs. Note: the parameter should be typed as either integer or string -- use a union-style description since JSON Schema in OpenAI tools handles this via description guidance rather than `oneOf` (which is not well-supported without strict mode).

3. `query_alerts` -- params: time_window (enum), min_severity (enum), limit (integer, default 20, max 100). Description differentiates alerts from incidents for the LLM.

4. `get_alert_trend` -- params: time_window (enum), min_severity (enum), bin_size (string, optional -- "1h" or "1d", auto-selected if omitted). Description guides usage for trend/pattern questions.

5. `get_top_entities` -- params: time_window (enum), min_severity (enum), limit (integer, default 10, max 50). Description guides usage for "most targeted", "top attackers", entity-related questions.

CRITICAL constraints (from research):
- Do NOT use `strict: true` on any tool schema (incompatible with parallel tool calls)
- Do NOT set `parallel_tool_calls` parameter (let gpt-4o default behavior handle it)
- Use `"type": "function"` wrapper format
- Enum values for time_window: ["last_1h", "last_24h", "last_3d", "last_7d", "last_14d", "last_30d"]
- Enum values for min_severity: ["High", "Medium", "Low", "Informational"]
- Only `time_window` should be required for query_incidents, query_alerts, get_alert_trend, get_top_entities
- Only `incident_ref` should be required for get_incident_detail

Also create a helper: `get_tool_names() -> list[str]` that returns the list of all tool function names (useful for validation).

**src/tool_handlers.py** -- Create ToolDispatcher class:

```python
class ToolDispatcher:
    def __init__(self, sentinel_client: SentinelClient):
        # Map tool names to handler methods
        self._client = sentinel_client
        self._dispatch_map = {
            "query_incidents": self._query_incidents,
            "get_incident_detail": self._get_incident_detail,
            "query_alerts": self._query_alerts,
            "get_alert_trend": self._get_alert_trend,
            "get_top_entities": self._get_top_entities,
        }

    def dispatch(self, tool_name: str, arguments: dict) -> dict:
        """Dispatch a tool call. Returns a dict suitable for JSON serialization.

        - Unknown tool names return {"error": "Unknown tool: {name}"}
        - Retryable errors are retried once silently (per user decision)
        - All results come from .to_dict() on QueryResult/QueryError
        """

    def get_status_message(self, tool_name: str) -> str:
        """Return a user-facing status message for tool execution.
        e.g., "Querying incidents..." for query_incidents
        """
```

Each handler method extracts arguments with sensible defaults matching SentinelClient signatures:
- `_query_incidents(args)`: time_window default "last_24h", min_severity default "Informational", limit default 20
- `_get_incident_detail(args)`: incident_ref is required (return error dict if missing). Handle both int and str types -- if the value is a string that looks like a number, convert to int.
- `_query_alerts(args)`: same defaults as query_incidents
- `_get_alert_trend(args)`: time_window default "last_7d", min_severity default "Informational", bin_size default None (let SentinelClient auto-select)
- `_get_top_entities(args)`: time_window default "last_7d", min_severity default "Informational", limit default 10

Retry logic: After calling the SentinelClient method, check if result is QueryError with retry_possible=True. If so, retry once silently. Return the result of the retry (whether success or failure). This matches the user decision: "retry silently once on failure, then explain the error clearly."

Status messages (for Phase 3 simple text output per user decision):
- query_incidents -> "Querying incidents..."
- get_incident_detail -> "Looking up incident details..."
- query_alerts -> "Querying alerts..."
- get_alert_trend -> "Analyzing alert trends..."
- get_top_entities -> "Finding top targeted entities..."

**requirements.txt** -- Add `tiktoken>=0.12.0` line (needed by Plan 03-02 for token counting, install now to keep deps current).
  </action>
  <verify>
Run `python -c "from src.tools import SENTINEL_TOOLS, get_tool_names; print(len(SENTINEL_TOOLS), get_tool_names())"` -- should print 5 tools and the 5 function names.
Run `python -c "from src.tool_handlers import ToolDispatcher; print('OK')"` -- should import without error.
Run `pip install -r requirements.txt` to verify tiktoken installs.
  </verify>
  <done>SENTINEL_TOOLS has 5 tool definitions with correct schemas. ToolDispatcher routes all 5 tool names to SentinelClient methods. Unknown tools return error dicts. Retryable errors trigger one silent retry. tiktoken is in requirements.txt.</done>
</task>

<task type="auto">
  <name>Task 2: System prompt and templates</name>
  <files>src/prompts.py</files>
  <action>
Create src/prompts.py with the following constants:

**SYSTEM_PROMPT** -- The main system prompt for the Sentinel chatbot. This is Claude's discretion for exact wording, but MUST include these locked requirements:

1. **Role definition**: You are a security operations assistant for Microsoft Sentinel. You help SOC analysts query and understand their security data.

2. **Grounding rules (HARD -- from user decisions)**:
   - ONLY present facts from tool call results. Never fabricate incident numbers, severities, timestamps, entity names, or any other data.
   - If asked to provide examples or sample data, respond: "I can't provide example data to prevent context poisoning. Let me query some real data for you instead."
   - If a query returns empty results, state this clearly and suggest alternatives (broaden severity, expand time range).
   - All AI-generated analysis must include a note that findings should be verified by a human analyst before taking action.

3. **Response style (from user decisions)**:
   - Present data with brief context and interpretation (explanatory, not terse, not verbose walkthrough)
   - Use footnote-style reasoning transparency: answer first, then below list which tools were called and what data was retrieved in a "---\nData sources:" section
   - Format data in basic readable tables when presenting lists (plain text tables, not rich -- rich formatting comes in Phase 5)
   - Only suggest follow-up questions when helpful for complex results, not after every response
   - Number results in lists with [1], [2], [3] format so users can reference them (e.g., "tell me more about [2]")

4. **Conversation behavior (from user decisions)**:
   - Support both implicit references ("tell me more about that incident") and numbered references ("[2]") to previous results
   - When the user references a previous result, use the appropriate detail tool to get more information
   - After gathering sufficient data from tools, synthesize findings into a response. Do not call additional tools unless the data is insufficient.

5. **Out-of-scope handling (from user decisions)**:
   - If asked about topics outside Sentinel security data, explain what you CAN do, keep it friendly with appropriate humor
   - Light jokes and puns are encouraged; keep it professional

6. **Tool usage guidance**:
   - You have access to tools for querying Microsoft Sentinel security data
   - Choose the most appropriate tool based on the user's question
   - For broad "what's happening" questions, query_incidents with last_24h is a good default
   - For trend analysis or pattern questions, use get_alert_trend
   - For entity-focused questions ("who is being targeted"), use get_top_entities

**TOKEN_WARNING** -- String template: "Your conversation is getting long. Older messages will be trimmed to keep things running smoothly."

**MAX_ROUNDS_MESSAGE** -- String template: "I've reached the maximum number of tool calls for this turn. Here's what I found so far:"

**CLEAR_SUMMARY_TEMPLATE** -- String template for /clear summary generation: "Summarize the key discussion items, findings, and any user preferences from this conversation in 2-3 concise sentences. Focus on what would be useful context if the conversation were to continue."

**DISCLAIMER** -- String constant: "Note: AI-generated analysis should be verified by a human analyst before taking action."
  </action>
  <verify>
Run `python -c "from src.prompts import SYSTEM_PROMPT, TOKEN_WARNING, MAX_ROUNDS_MESSAGE, CLEAR_SUMMARY_TEMPLATE, DISCLAIMER; print('All prompts loaded'); assert 'fabricat' in SYSTEM_PROMPT.lower() or 'context poisoning' in SYSTEM_PROMPT.lower(); print('Grounding rule present')"` -- should confirm all constants exist and grounding rule is present.
  </verify>
  <done>SYSTEM_PROMPT contains all 6 sections (role, grounding, response style, conversation behavior, out-of-scope handling, tool guidance). TOKEN_WARNING, MAX_ROUNDS_MESSAGE, CLEAR_SUMMARY_TEMPLATE, and DISCLAIMER constants exist. No-fabrication hard rule is explicit in the system prompt.</done>
</task>

<task type="auto">
  <name>Task 3: Tests for tools, dispatch, and prompts</name>
  <files>tests/test_tools.py, tests/test_tool_handlers.py, tests/test_prompts.py</files>
  <action>
**tests/test_tools.py** -- Test the tool definitions:
- Test SENTINEL_TOOLS has exactly 5 entries
- Test each tool has type="function" and a "function" key with "name", "description", "parameters"
- Test tool names match expected: query_incidents, get_incident_detail, query_alerts, get_alert_trend, get_top_entities
- Test get_tool_names() returns the correct 5 names
- Test no tool has "strict" key set to true (critical constraint)
- Test time_window enum values match TIME_WINDOWS keys from src/queries/__init__.py
- Test min_severity enum values match SEVERITY_ORDER from src/queries/__init__.py (but in reverse display order: High, Medium, Low, Informational)
- Test query_incidents, query_alerts, get_alert_trend, get_top_entities each have "time_window" as required
- Test get_incident_detail has "incident_ref" as required

**tests/test_tool_handlers.py** -- Test the dispatcher:
- Create a mock SentinelClient (or use unittest.mock to mock one) that returns known QueryResult/QueryError objects
- Test dispatch("query_incidents", {"time_window": "last_24h"}) calls sentinel_client.query_incidents with correct args and returns .to_dict() result
- Test dispatch("get_incident_detail", {"incident_ref": 42}) calls get_incident_detail(42)
- Test dispatch("get_incident_detail", {"incident_ref": "phishing"}) calls get_incident_detail("phishing")
- Test dispatch("get_incident_detail", {"incident_ref": "42"}) converts string "42" to int 42 (numeric string detection)
- Test dispatch("unknown_tool", {}) returns {"error": "Unknown tool: unknown_tool"}
- Test silent retry: mock SentinelClient to return QueryError(retry_possible=True) on first call, then QueryResult on second call. Verify dispatch returns the successful QueryResult.
- Test retry exhaustion: mock SentinelClient to return QueryError(retry_possible=True) on both calls. Verify dispatch returns the error.
- Test non-retryable error: mock to return QueryError(retry_possible=False). Verify only one call is made (no retry).
- Test get_status_message returns correct strings for each tool name
- Test get_status_message returns a generic message for unknown tools

Use `unittest.mock.MagicMock` for the SentinelClient mock. Create QueryResult and QueryError instances directly from src.models.

**tests/test_prompts.py** -- Test prompt content:
- Test SYSTEM_PROMPT is a non-empty string
- Test SYSTEM_PROMPT contains key grounding phrases (at least one of: "fabricat", "context poisoning", "never fabricat")
- Test SYSTEM_PROMPT contains footnote/transparency instruction (at least one of: "Data sources", "tools", "footnote")
- Test SYSTEM_PROMPT contains numbered reference instruction ("[1]" or "number" near "results")
- Test TOKEN_WARNING is a non-empty string
- Test MAX_ROUNDS_MESSAGE is a non-empty string
- Test CLEAR_SUMMARY_TEMPLATE is a non-empty string
- Test DISCLAIMER contains "verified" or "human analyst"
  </action>
  <verify>
Run `pytest tests/test_tools.py tests/test_tool_handlers.py tests/test_prompts.py -v` -- all tests pass.
Run `pytest` -- full test suite still passes (no regressions).
  </verify>
  <done>All tool definition tests pass (schema structure, no strict:true, enum values match queries module). All dispatch tests pass (routing, retry logic, error handling, numeric string conversion). All prompt tests pass (grounding rules, transparency, templates exist). Full test suite green.</done>
</task>

</tasks>

<verification>
1. `python -c "from src.tools import SENTINEL_TOOLS; print(len(SENTINEL_TOOLS))"` prints 5
2. `python -c "from src.tool_handlers import ToolDispatcher; print('OK')"` imports cleanly
3. `python -c "from src.prompts import SYSTEM_PROMPT; print(len(SYSTEM_PROMPT))"` shows substantial prompt length
4. `pytest tests/test_tools.py tests/test_tool_handlers.py tests/test_prompts.py -v` -- all green
5. `pytest` -- full suite green, no regressions
6. `ruff check src/tools.py src/tool_handlers.py src/prompts.py` -- no lint errors
</verification>

<success_criteria>
- 5 tool definitions in SENTINEL_TOOLS matching SentinelClient's 5 methods, no strict:true
- ToolDispatcher correctly routes all 5 tools with retry logic
- System prompt contains hard no-fabrication rule, footnote transparency, numbered results
- All new tests pass, no regressions in existing tests
</success_criteria>

<output>
After completion, create `.planning/phases/03-ai-orchestration-integration/03-01-SUMMARY.md`
</output>
